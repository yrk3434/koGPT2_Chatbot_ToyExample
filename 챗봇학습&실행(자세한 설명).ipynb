{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# koGPT2를 이용한 챗봇 학습 & 테스트 실습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- koGPT2를 사전학습 모델로 두고, 별도 데이터를 이용해 추가 학습(fine tuning)을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# !pip install pytorch_lightning==1.6.0 버전으로 받기\n",
    "# ->  pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import PreTrainedTokenizerFast,GPT2LMHeadModel\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from preprocess.clean_data import ChatbotDataset\n",
    "from fine_tuning.train import collate_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. 데이터 불러오기(추가 학습용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# 실행시 현재 파일과 같은 경로에 ChatBotData.csv 파일 생성됨\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
    "    filename=\"ChatBotData.csv\",\n",
    ")\n",
    "Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n",
    "\n",
    "# Test 용으로 300개 데이터만 처리한다.\n",
    "Chatbot_Data = Chatbot_Data[:300]\n",
    "Chatbot_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n",
    "\n",
    "#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n",
    "num_workers = 2\n",
    "train_dataloader = DataLoader(train_set, \n",
    "                              batch_size=32, \n",
    "                              num_workers=num_workers, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=collate_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>궁금하지?</td>\n",
       "      <td>안 궁금해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>궁금해</td>\n",
       "      <td>자세히 말씀해주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>궁금해 알려줘</td>\n",
       "      <td>자세히 말씀해주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>귀 아파</td>\n",
       "      <td>병원에 가세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>귀가 가려워</td>\n",
       "      <td>누가 욕하고 있나봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Q             A  label\n",
       "0             12시 땡!    하루가 또 가네요.      0\n",
       "1        1지망 학교 떨어졌어     위로해 드립니다.      0\n",
       "2       3박4일 놀러가고 싶다   여행은 언제나 좋죠.      0\n",
       "3    3박4일 정도 놀러가고 싶다   여행은 언제나 좋죠.      0\n",
       "4            PPL 심하네    눈살이 찌푸려지죠.      0\n",
       "..               ...           ...    ...\n",
       "295            궁금하지?       안 궁금해요.      0\n",
       "296              궁금해   자세히 말씀해주세요.      0\n",
       "297          궁금해 알려줘   자세히 말씀해주세요.      0\n",
       "298             귀 아파      병원에 가세요.      0\n",
       "299           귀가 가려워  누가 욕하고 있나봐요.      0\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set._data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 전처리: ChatbotDataset 클래스로 train set 처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 방식\n",
    "- 대화의 Question, Answer을 토큰화 후 ID로 변환(숫자 딕셔너리 데이터)\n",
    "- 데이터 길이 표준화(padding)\n",
    "\n",
    "### 함수 구조\n",
    "- __getitem__의 인풋으로 dataframe의 row 번호를 넣으면 질문+답변, 마스크, 답변 r개요eturn\n",
    "    - 단, 질문+답변: index 로 만든 질문+답변   <br/>\n",
    "    -> token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
    "    - 단, mask = 질문길이 0 + 답변길이 1 + 나머지 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q            12시 땡!\n",
      "A        하루가 또 가네요.\n",
      "label             0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_tmp = train_set._data.iloc[idx]\n",
    "print(data_tmp)\n",
    "# Q: 질문\n",
    "# A: 답변"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 전처리 프로세스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 토큰화 전 raw data(대화의 Question): 12시 땡 \n",
      "   > 참고. ChatbotDataset class에 선언된 q token: <usr>\n",
      "   > 참고. ChatbotDataset class에 선언된 sent token: <unused1>\n",
      "2. tokenizer에 들어갈 인풋: <usr>12시 땡 <unused1>\n",
      "3. 토크나이징 결과: ['<usr>', '▁12', '시', '▁', '땡', '▁', '<unused1>']\n",
      "4. 토큰을 ID로 변환: [2, 9349, 7888, 739, 7318, 739, 10]\n"
     ]
    }
   ],
   "source": [
    "q = data_tmp[\"Q\"]  # 질문을 가져온다.\n",
    "q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n",
    "print(\"1. 토큰화 전 raw data(대화의 Question):\",q)\n",
    "\n",
    "print(\"   > 참고. ChatbotDataset class에 선언된 q token:\", train_set.q_token)\n",
    "print(\"   > 참고. ChatbotDataset class에 선언된 sent token:\", train_set.sent_token)\n",
    "input_tmp = train_set.q_token + q + train_set.sent_token\n",
    "print(\"2. tokenizer에 들어갈 인풋:\",input_tmp)\n",
    "q_toked = train_set.tokenizer.tokenize(input_tmp)\n",
    "print(\"3. 토크나이징 결과:\", q_toked)\n",
    "print(\"4. 토큰을 ID로 변환:\", train_set.tokenizer.convert_tokens_to_ids(q_toked))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 전처리 결과 해석\n",
    "1. raw data -> ID\n",
    "2. 문장 길이 통일을 위한 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. token_ids(질문+답변): [2, 9349, 7888, 739, 7318, 739, 10, 4, 12557, 6824, 9108, 9028, 7098, 8084, 739, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "   > 참고. 문장 패딩 토큰 ID: 3\n",
      "    -> 위 리스트에서 3은 빈 칸을 패딩한 것\n",
      "   > 참고. 2 ~ 4까지가 질문에 해당하는 ID, 12557 ~ 1까지가 답변에 해당하는 ID\n",
      "2. mask(질문0+답변1+나머지단어0으로 패딩): [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "   > 참고. Q 원 데이터: 학교종이 땡\n",
      "   > 참고. Q 토큰화 데이터: ['<usr>', '▁12', '시', '▁', '땡', '▁', '<unused1>']\n",
      "    -> 리스트 내 7개의 element를 [0 0 0 0 0 0 0] 마스크로 표현\n",
      "3. label: [9, 9, 9, 9, 9, 9, 9, 12557, 6824, 9108, 9028, 7098, 8084, 739, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#질문+답변, 마스크, 답변\n",
    "token_ids, mask, label = train_set.__getitem__(idx)\n",
    "print(f\"1. token_ids(질문+답변): {token_ids}\") # 12시 땡! + 하루가 또 가네요.\t\n",
    "print(f\"   > 참고. 문장 패딩 토큰 ID: {train_set.tokenizer.pad_token_id}\")\n",
    "print(\"    -> 위 리스트에서 3은 빈 칸을 패딩한 것\")\n",
    "print(f\"   > 참고. 2 ~ 4까지가 질문에 해당하는 ID, 12557 ~ 1까지가 답변에 해당하는 ID\")\n",
    "print(f\"2. mask(질문0+답변1+나머지단어0으로 패딩): {mask}\")\n",
    "print(f\"   > 참고. Q 원 데이터: 학교종이 땡\")\n",
    "print(f\"   > 참고. Q 토큰화 데이터: {q_toked}\")\n",
    "print(\"    -> 리스트 내 7개의 element를 [0 0 0 0 0 0 0] 마스크로 표현\")\n",
    "print(\"3. label:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 문장 길이: 40\n",
      "- token_ids 리스트 길이: 40\n"
     ]
    }
   ],
   "source": [
    "print(f\"- 문장 길이: {train_set.max_len}\")\n",
    "print(f\"- token_ids 리스트 길이: {len(token_ids)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. 모델 추가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train() # 추가 학습 준비\n",
    "\n",
    "# 아래 프린트된 결과는 사전 학습 모델의 구조"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 관련 파라미터 및 학습 방법(loss, optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch = 10\n",
    "Sneg = -1e18\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고. 파이토치에서는 backward() 함수, 즉 오차 역전파를 이용해 추가 학습 코드 만듦\n",
    "- 아래는 PyTorch를 사용하여 기존 모델에 추가 학습을 적용하는 예시 코드([참고. pytorch 페이지](https://discuss.pytorch.kr/t/topic/2980/3))\n",
    "    ~~~python\n",
    "\n",
    "    import torch\n",
    "    from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "    # 모델과 토크나이저 로드\n",
    "    model_name = 'xwin-mlewd-13b-v0.2.Q8_0.gguf'\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    # 새로운 데이터셋 준비\n",
    "    new_data = [\"새로운 소설 데이터 1\", \"새로운 소설 데이터 2\", ...]\n",
    "\n",
    "    # 데이터 전처리 및 토큰화\n",
    "    encoded_new_data = [tokenizer.encode(data, add_special_tokens=True) for data in new_data]\n",
    "\n",
    "    # DataLoader를 사용하여 학습 데이터 준비\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    input_ids = torch.tensor(encoded_new_data)\n",
    "    dataset = TensorDataset(input_ids)\n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 추가 학습 시작\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in data_loader:\n",
    "            inputs = batch[0].to(model.device)\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print(f\"Epoch {epoch} Loss {loss.item()}\")\n",
    "\n",
    "    # 모델 저장\n",
    "    model.save_pretrained('my_finetuned_model')\n",
    "~~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### 아래 loop를 통한 학습 과정을 line by line으로 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "print (\"start\")\n",
    "for epoch in range(epoch):\n",
    "    for batch_idx, samples in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids, mask, label = samples\n",
    "        out = model(token_ids)\n",
    "        out = out.logits      #Returns a new tensor with the logit of the elements of input\n",
    "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
    "        loss = criterion(mask_out.transpose(2, 1), label)\n",
    "        # ---  평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\n",
    "        avg_loss = loss.sum() / mask.sum()\n",
    "        avg_loss.backward()\n",
    "        # --- 학습 끝\n",
    "        optimizer.step()\n",
    "print (\"end\")\n",
    "~~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배치 데이터 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/Users/yurikim/Desktop/study/koGPT2_ChatBot_ToyExample(local)/fine_tuning/train.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
      "/Users/yurikim/Desktop/study/koGPT2_ChatBot_ToyExample(local)/fine_tuning/train.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 (tensor([[    2, 18351, 15413, 13340, 14807,    10,     4, 18351, 23638,  9337,\n",
      "         11166, 12249,  8084,   739,     1,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2,  9244,  6958, 21246, 10811,    10,     4, 15365,  6824,  7801,\n",
      "          8084,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2, 41998, 21716, 46339,  9456,  6853,  7991,    10,     4, 10556,\n",
      "          9325, 46339,  9114,  6962, 13158,  8084,   739,     1,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2,  9226,  7889, 46651, 17003,  6969,    10,     4,  9163,  8278,\n",
      "          9021,  9174,  9086, 11594,  6866, 31961,  8234,   739,     1,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2,  9020,  8263,  7497, 10192, 11615,  8210,  8006,    10,     4,\n",
      "         12422,  8711,  9535,  7483,  7172,  7182,   739,     1,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2, 10715,  9511, 15730, 21336,  6969,   739,    10,     4,  9179,\n",
      "         10134, 15730,  8143, 14304, 10544,  6872,  9176, 15730,  8705,  9122,\n",
      "          8046,  8084,   739,     1,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2, 49300,  7250,  8006,    10,     4, 14821,  9024,  8239, 39783,\n",
      "         10345,  9049,  7801,  8084,   468,     1,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2, 25883, 14701,  7991,    10,     4, 10586,  9802,  9846,  9122,\n",
      "          8046,  8084,   739,     1,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2,   739,  6910,  8811,  9193,  7285,  8263, 43285,    10,     4,\n",
      "          9564,  9027,  8378,  7055,  7661,  8084,   739,     1,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2, 21435, 11950, 45231,   216,    10,     4,  9410,  7605,  8570,\n",
      "          9069,  9495, 13400, 10460,  6872,  8006,  8084,   739,     1,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2, 15983,  7673, 24648, 15010, 10926,  6853, 27511,    10,     4,\n",
      "         16173, 15582, 46439, 35557,  6889, 12252,  7801,  8084,   739,     1,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    2,  9244,  7584,  9520, 48213, 12011,    10,     4,  9265,  7235,\n",
      "         12904, 13358,  7098,  8084,   739,     1,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]]), tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([[    9,     9,     9,     9,     9,     9, 18351, 23638,  9337, 11166,\n",
      "         12249,  8084,   739,     1,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9, 15365,  6824,  7801,  8084,\n",
      "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,     9, 10556,  9325,\n",
      "         46339,  9114,  6962, 13158,  8084,   739,     1,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,  9163,  8278,  9021,\n",
      "          9174,  9086, 11594,  6866, 31961,  8234,   739,     1,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,     9,     9, 12422,\n",
      "          8711,  9535,  7483,  7172,  7182,   739,     1,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,     9,  9179, 10134,\n",
      "         15730,  8143, 14304, 10544,  6872,  9176, 15730,  8705,  9122,  8046,\n",
      "          8084,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9, 14821,  9024,  8239, 39783, 10345,\n",
      "          9049,  7801,  8084,   468,     1,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9, 10586,  9802,  9846,  9122,  8046,\n",
      "          8084,   739,     1,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,     9,     9,  9564,\n",
      "          9027,  8378,  7055,  7661,  8084,   739,     1,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,  9410,  7605,  8570,  9069,\n",
      "          9495, 13400, 10460,  6872,  8006,  8084,   739,     1,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,     9,     9, 16173,\n",
      "         15582, 46439, 35557,  6889, 12252,  7801,  8084,   739,     1,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
      "        [    9,     9,     9,     9,     9,     9,     9,  9265,  7235, 12904,\n",
      "         13358,  7098,  8084,   739,     1,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]]))\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, samples in enumerate(train_dataloader):\n",
    "    pass\n",
    "print(batch_idx, samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. 추가 학습 데이터 중 일부(2개)만 가져와 사전학습 모델에 추가되는 과정 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids, mask, label = samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추가 학습 데이터를 2개씩만 넣어서 추가 학습 프로세스 line by line으로 확인\n",
    "    - 단, token_ids는 질문+답변+패딩으로 이루어진 토큰의 ID\n",
    "- 참고. 사전학습 모델의 결과의 차원은 51,200\n",
    "    - (lm_head): Linear(in_features=768, out_features=51200, bias=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Predict: token ID(전처리 결과)가 사전학습 모델을 거쳐 output shape이 51,200인 텐서 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- token ID: tensor([    2, 18351, 15413, 13340, 14807,    10,     4, 18351, 23638,  9337,\n",
      "        11166, 12249,  8084,   739,     1,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3])\n",
      "   > 참고. 인풋 토큰 아이디의 shape: torch.Size([40])\n",
      "- 사전학습 모델의 seq2seq 결과(로지스틱 변환): tensor([[[-5.6972, -5.7120, -4.1977,  ..., -1.4714, -2.5882, -1.3944],\n",
      "         [-6.3349, -3.8235, -6.3412,  ..., -0.9051, -3.3118, -3.8610],\n",
      "         [-4.1912, -5.0025, -5.3797,  ...,  0.7796, -2.1561, -2.0131],\n",
      "         ...,\n",
      "         [-1.3315,  0.3779, -0.7495,  ..., -0.4581,  4.5130, -1.9160],\n",
      "         [-0.5138,  1.4653, -0.7271,  ...,  0.3596,  4.7405, -1.0524],\n",
      "         [-0.7479,  0.3439, -0.2152,  ..., -0.5346,  3.6110, -0.2688]],\n",
      "\n",
      "        [[-6.5312, -6.2856, -4.6215,  ..., -0.9085, -3.4982, -1.7145],\n",
      "         [-3.7405, -5.1162, -3.7704,  ..., -5.7269, -3.5622, -3.1481],\n",
      "         [-7.9146, -6.6885, -6.6951,  ..., -2.6281, -3.8640, -4.4799],\n",
      "         ...,\n",
      "         [-0.1873,  1.3129, -0.2787,  ...,  1.3385,  3.7144,  0.1865],\n",
      "         [-0.9126,  0.6813, -0.5237,  ..., -0.3393,  3.0638,  0.3486],\n",
      "         [-0.6329,  0.5801, -0.6629,  ..., -0.4619,  3.2844, -0.2190]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "   > 참고. 사전학습 모델 결과의 shape: torch.Size([2, 40, 51200])\n"
     ]
    }
   ],
   "source": [
    "print(f\"- token ID: {token_ids[0]}\")\n",
    "print(f\"   > 참고. 인풋 토큰 아이디의 shape: {token_ids[0].shape}\")\n",
    "out = model(token_ids[:2]).logits\n",
    "print(f\"- 사전학습 모델의 seq2seq 결과(로지스틱 변환): {out}\")\n",
    "print(f\"   > 참고. 사전학습 모델 결과의 shape: {out.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) PREDICT 결과 포맷 조정: \n",
    "#### -> mask(질문 & 답변 길이 관련 벡터)의 차원을 token ID 결과와 맞춤 <br/> (단어가 있는 위치(질문0, 답변1) & 빈 칸(0)이 있는 위치 구분)\n",
    "- 마지막 차원의 길이 51,200로 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- mask(질문0+답변1+나머지단어0으로 패딩): tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "   > 참고. mask의 shape: torch.Size([2, 40])\n",
      "- mask_3d: tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]])\n",
      "   > 참고. 사전학습 모델 결과의 shape: torch.Size([2, 40, 51200])\n",
      "   > 예. 첫번째 데이터의 5번째 mask element(질문 토큰 위치): tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "   > 예. 첫번째 데이터의 8번째 mask element(답변 토큰 위치): tensor([1, 1, 1,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"- mask(질문0+답변1+나머지단어0으로 패딩): {mask[:2]}\")\n",
    "print(f\"   > 참고. mask의 shape: {mask[:2].shape}\")\n",
    "\n",
    "mask_3d = mask[:2].unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "print(f\"- mask_3d: {mask_3d}\")\n",
    "print(f\"   > 참고. 사전학습 모델 결과의 shape: {mask_3d.shape}\")\n",
    "print(f\"   > 예. 첫번째 데이터의 5번째 mask element(질문 토큰 위치): {mask_3d[0][4]}\")\n",
    "print(f\"   > 예. 첫번째 데이터의 8번째 mask element(답변 토큰 위치): {mask_3d[0][12]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) PREDICT 결과 포맷 조정: \n",
    "#### -> 실제 단어가 있는 위치에만 모델 결과를 넣고 빈 칸은 0에 가까운 수 넣기\n",
    "- mask 내 element 중\n",
    "    - 실제 단어가 있는 위체 element에는 out(사전학습 모델 결과)를 반환하고, \n",
    "    - 빈칸을 padding으로 부분은 0에 가까운 아주 작은 수 Sneg(-1e+18)를 넣는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 단어 위치(질문, 답변, 빈 칸) 고려 결과 조정: tensor([[[-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         ...,\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18]],\n",
      "\n",
      "        [[-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         ...,\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18],\n",
      "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "          -1.0000e+18, -1.0000e+18]]], grad_fn=<WhereBackward0>)\n",
      "- 단어 위치 텐서의 shape: torch.Size([2, 40, 51200])\n"
     ]
    }
   ],
   "source": [
    "#  torch.where: where(condition, input, other, *, out=None) -> Tensor\n",
    "#       -> Return a tensor of elements selected from either :attr:`input` or :attr:`other`, depending on :attr:`condition`.\n",
    "# --- 단어 element가 있는 부분에는 out(사전학습 모델 결과)를 반환하고, 빈칸이어서 padding인 부분은 0에 가까운 아주 작은 수 Sneg(-1e+18)를 넣는다\n",
    "mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
    "\n",
    "print(f\"- 단어 위치(질문, 답변, 빈 칸) 고려 결과 조정: {mask_out}\")\n",
    "print(f\"- 단어 위치 텐서의 shape: {mask_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > 예. 첫번째 데이터의 5번째 mask element(질문 토큰 위치): tensor([-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
      "        -1.0000e+18, -1.0000e+18], grad_fn=<SelectBackward0>)\n",
      "   > 예. 첫번째 데이터의 8번째 mask element(답변 토큰 위치): tensor([-4.4155, -4.1209, -4.4621,  ...,  0.0094, -4.1377, -4.1392],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"   > 예. 첫번째 데이터의 5번째 mask element(질문 토큰 위치): {mask_out[0][4]}\")\n",
    "print(f\"   > 예. 첫번째 데이터의 8번째 mask element(답변 토큰 위치): {mask_out[0][12]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) LOSS 계산\n",
    "#### -> Pedict 결과와 답변(answer) 간 차이"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 답변(true y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    9,     9,     9,     9,     9,     9, 18351, 23638,  9337, 11166,\n",
       "         12249,  8084,   739,     1,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
       "        [    9,     9,     9,     9,     9,     9, 15365,  6824,  7801,  8084,\n",
       "           739,     1,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 40])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:2].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Question에 따른 예측값(predicted y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         ...,\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18]],\n",
       "\n",
       "        [[-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         ...,\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18],\n",
       "         [-1.0000e+18, -1.0000e+18, -1.0000e+18,  ..., -1.0000e+18,\n",
       "          -1.0000e+18, -1.0000e+18]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_out.transpose(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 51200, 40])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_out.transpose(2, 1).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고. criterion은 torch.nn.CrossEntropyLoss(reduction=\"none\")으로 위에서 선언\n",
    "    - 크로스엔트로피를 통해 predict 결과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(mask_out.transpose(2, 1), label[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435,  9.3041,  2.7851,\n",
       "          6.4304,  4.0772,  5.9460,  8.1183,  4.1581, 17.1258, 14.9869, 10.8435,\n",
       "         10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435,\n",
       "         10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435,\n",
       "         10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435],\n",
       "        [10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8989,  7.3553,\n",
       "          8.0691,  5.7411,  2.7540, 15.5434, 14.9512, 10.8435, 10.8435, 10.8435,\n",
       "         10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435,\n",
       "         10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435,\n",
       "         10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435, 10.8435]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) loss를 역전파 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52.0143, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss = loss.sum() / mask[:2].sum()\n",
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() # 학습 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파일저장\n",
    " \n",
    "# import pickle\n",
    "\n",
    "model_pkl_file = \"./checkpoints/GPT2LMHeadModel.pkl\"  \n",
    "\n",
    "# with open(model_pkl_file, 'wb') as file:  \n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 학습 & 저장 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_model(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. 학습 모델(fine tuning 결과) 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "Q_TKN = \"<usr>\"\n",
    "A_TKN = \"<sys>\"\n",
    "BOS = '</s>'\n",
    "EOS = '</s>'\n",
    "MASK = '<unused0>'\n",
    "SENT = '<unused1>'\n",
    "PAD = '<pad>'\n",
    "\n",
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=BOS, eos_token=EOS, \n",
    "            unk_token='<unk>', # out of vacabulary token\n",
    "            pad_token=PAD, mask_token=MASK) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 프롬프트를 인풋으로 받는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Forward raw_input to frontends\n",
      "\n",
      "Raises\n",
      "------\n",
      "StdinNotImplementedError if active frontend doesn't support stdin.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/py_3_8/lib/python3.8/site-packages/ipykernel/kernelbase.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "            bos_token=BOS, eos_token=EOS, \n",
    "            # unk_token='<unk>', # out of vacabulary token\n",
    "            pad_token=PAD, mask_token=MASK) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 챗봇 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안녕 친구야 반가워\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 1\n",
    "with torch.no_grad():\n",
    "    while 1:\n",
    "        q = input(\"user > \").strip()\n",
    "        if q == \"quit\":\n",
    "            break\n",
    "        a = \"\"\n",
    "        while 1: # 문장 끝맺음(EOS)까지 무한 루프\n",
    "            # input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + sent + A_TKN + a)).unsqueeze(dim=0)\n",
    "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT +  A_TKN + a)).unsqueeze(dim=0)\n",
    "            pred = model(input_ids)\n",
    "            pred = pred.logits\n",
    "            \n",
    "            # 생성된 값 중 가장 확률이 높은 단어 가져오기\n",
    "            gen_list = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist()) # 결과 확인용\n",
    "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n",
    "\n",
    "            if gen == EOS:\n",
    "                break\n",
    "            \n",
    "            # gen에서 고른 확률 높은 답변(단어) 추가\n",
    "            a += gen.replace(\"▁\", \" \").replace('<unk>','')\n",
    "            # if idx ==100:\n",
    "            #     print(\"-----------------------\")\n",
    "            #     print(f\"input: {Q_TKN + q + SENT + A_TKN + a}\")\n",
    "            #     # print(f\"gen: {gen_list}\")\n",
    "            #     print(f\"a: {a}\")\n",
    "            #     break\n",
    "            # idx+=1\n",
    "        print(f\"input: {Q_TKN + q + SENT + A_TKN + a}\")\n",
    "        print(\"Chatbot > {}\".format(a.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f541650a259d3c85c16fa389922248120f711c850d1b246e80025daa1aee6568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
